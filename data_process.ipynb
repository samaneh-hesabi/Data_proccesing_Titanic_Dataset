{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24069/638182231.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(avg_fare=group['fare'].mean()))  # Compute avg fare\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex  sibsp  parch     fare embarked class_grouped  \\\n",
      "0         1       1  FEMALE      1      0  71.2833        C         First   \n",
      "1         1       1  FEMALE      1      0  71.2833        C         First   \n",
      "2         1       1  FEMALE      1      0  71.2833        C         First   \n",
      "3         1       1  FEMALE      1      0  71.2833        C         First   \n",
      "4         1       1  FEMALE      1      0  71.2833        C         First   \n",
      "\n",
      "     who  adult_male deck embark_town alive  alone   avg_fare class_original  \\\n",
      "0  WOMAN       False    C   CHERBOURG   YES  False  96.342988          First   \n",
      "1  WOMAN       False    C   CHERBOURG   YES  False  96.342988         Second   \n",
      "2  WOMAN       False    C   CHERBOURG   YES  False  96.342988          Third   \n",
      "3  WOMAN       False    C   CHERBOURG   YES  False  96.342988          Third   \n",
      "4  WOMAN       False    C   CHERBOURG   YES  False  96.342988          First   \n",
      "\n",
      "   fare_original  \n",
      "0        71.2833  \n",
      "1        30.0708  \n",
      "2         7.2250  \n",
      "3         7.2250  \n",
      "4        27.7208  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "\n",
    "# Function to print details (fixing GroupBy issue)\n",
    "def print_details(dff, message1=\"\"):\n",
    "    \"\"\"\n",
    "    Prints a message, shape, and first row of a DataFrame (ignoring GroupBy objects).\n",
    "    \"\"\"\n",
    "    if isinstance(dff, pd.DataFrame):  # Check if it's a DataFrame\n",
    "        display(message1, dff.shape, dff.head(1))\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{message1} - This is a GroupBy object.\")\n",
    "    return dff\n",
    "\n",
    "# Applying method chaining on Titanic dataset\n",
    "result = (\n",
    "    df\n",
    "    #.pipe(print_details, \"Original DataFrame\")\n",
    "    .dropna(subset=['age', 'embark_town'])  # Remove missing values\n",
    "    #.pipe(print_details, \"Dropped missing values for 'age' and 'embark_town'\")\n",
    "    .query(\"age > 18\")  # Filter only adults\n",
    "    #.pipe(print_details, \"Filtered only adults\")\n",
    "    .groupby(['embark_town', 'sex'], as_index=False)  # Group by embark_town and sex\n",
    "    #.pipe(print_details, \"Grouped by 'embark_town' and 'sex'\")  # Will print group info\n",
    "    .apply(lambda group: group.assign(avg_fare=group['fare'].mean()))  # Compute avg fare\n",
    "    #.pipe(print_details, \"Assigned average fare per group\")\n",
    "    .reset_index(drop=True)  # Reset index after groupby\n",
    "    #.pipe(print_details, \"Reset index after groupby\")\n",
    "    .merge(df[['embark_town', 'class', 'fare']], on='embark_town', how='inner', suffixes=('_grouped', '_original'))  \n",
    "    #.pipe(print_details, \"Merged on 'embark_town' with 'class' and 'fare'\")\n",
    "    .drop(columns=['age'])  # Drop the 'age' column\n",
    "    #.pipe(print_details, \"Dropped 'age' column\")\n",
    "    .rename(columns={'fare_grouped': 'fare'})  # Rename column\n",
    "    #.pipe(print_details, \"Renamed 'fare_grouped' to 'fare'\")\n",
    "    .astype({'avg_fare': 'float'})  # Ensure correct data type\n",
    "    #.pipe(print_details, \"Casted 'avg_fare' column to float\")\n",
    ")\n",
    "\n",
    "# Apply string operations (uppercase) only to object (string) columns\n",
    "for col in result.select_dtypes(include=['object']).columns:\n",
    "    result[col] = result[col].str.upper()\n",
    "\n",
    "# Save to CSV\n",
    "result.to_csv(\"titanic_chain_rule_example.csv\", index=False)\n",
    "\n",
    "# Print the result\n",
    "print(result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 4 rows of the DataFrame\n",
      "(4, 4)\n",
      "  Student Subject  Score    City\n",
      "0     Ali    Math     85  Tehran\n",
      "Final Processed DataFrame:\n",
      "(3, 2)\n",
      "      City  Score\n",
      "0  Mashhad   90.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mashhad</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shiraz</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tehran</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City  Score\n",
       "0  Mashhad   90.0\n",
       "1   Shiraz   88.0\n",
       "2   Tehran   85.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Creating a small dataset\n",
    "data_dict = {\n",
    "    'Student': ['Ali', 'Sara', 'Ali', 'Reza', 'Mina', 'Sara', 'Reza', 'Omid'],\n",
    "    'Subject': ['Math', 'Physics', 'Math', 'Chemistry', 'Math', 'Physics', 'Math', 'Chemistry'],\n",
    "    'Score': [85, 90, 85, 88, 92, 90, 88, 95],\n",
    "    'City': ['Tehran', 'Mashhad', 'Tehran', 'Shiraz', 'Tehran', 'Mashhad', 'Shiraz', 'Mashhad'],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "def print_details(dff, message1=\"\"):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Prints a message, shape, and first row of a dataframe. Finally, returns the dataframe.\n",
    "    Parameters:\n",
    "        dff (dataframe)\n",
    "        message1 (str)\n",
    "    Returns:\n",
    "        dff (dataframe)\n",
    "    \"\"\"\n",
    "    print(message1)\n",
    "    print(dff.shape)\n",
    "    print(dff.head(1))\n",
    "    return dff\n",
    "\n",
    "# Chain rule (Chaining)\n",
    "df_processed = (\n",
    "    df\n",
    "    # Group 1: Basic Operations (head, tail, info, describe)\n",
    "    .head(4)  # First 4 rows\n",
    "    .pipe(print_details, \"First 4 rows of the DataFrame\")\n",
    "\n",
    "    # Group 2: Removing duplicates and creating new column\n",
    "    .drop_duplicates()  # Remove duplicates\n",
    "    #.pipe(print_details, \"After dropping duplicates\")\n",
    "\n",
    "    .assign(Passed=lambda x: x['Score'] > 85)  # Add new column 'Passed' based on Score\n",
    "    #.pipe(print_details, \"After adding 'Passed' column based on Score\")\n",
    "\n",
    "    # Group 3: Grouping and Aggregating Data\n",
    "    .groupby('City').agg({'Score': 'mean'})  # Average Score per City\n",
    "    #.pipe(print_details, \"Grouped by City with average Score\")\n",
    "\n",
    "    # Group 4: Type Conversion and Export\n",
    "    .reset_index()  # Reset index after grouping\n",
    "    .astype({'Score': 'float'})  # Type conversion for Score column\n",
    "    #.pipe(print_details, \"After type conversion\")\n",
    "    \n",
    "    # Saving the final DataFrame to CSV\n",
    "    .to_csv(\"df_processed.csv\", index=False)\n",
    ")\n",
    "\n",
    "# Load the processed DataFrame\n",
    "df_processed = pd.read_csv(\"df_processed.csv\")\n",
    "print_details(df_processed, \"Final Processed DataFrame:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Final Processed DataFrame:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Math</th>\n",
       "      <th>Physics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mashhad</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shiraz</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tehran</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City  Chemistry  Math  Physics\n",
       "0  Mashhad       95.0   NaN     90.0\n",
       "1   Shiraz       88.0  88.0      NaN\n",
       "2   Tehran        NaN  88.5      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Creating a small dataset\n",
    "data_dict = {\n",
    "    'Student': ['Ali', 'Sara', 'Ali', 'Reza', 'Mina', 'Sara', 'Reza', 'Omid'],\n",
    "    'Subject': ['Math', 'Physics', 'Math', 'Chemistry', 'Math', 'Physics', 'Math', 'Chemistry'],\n",
    "    'Score': [85, 90, 85, 88, 92, 90, 88, 95],\n",
    "    'City': ['Tehran', 'Mashhad', 'Tehran', 'Shiraz', 'Tehran', 'Mashhad', 'Shiraz', 'Mashhad'],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "\n",
    "\n",
    "def print_details(dff, message1=\"\"):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Prints a message, shape, and first row of a dataframe. Finally, returns the dataframe.\n",
    "    Parameters:\n",
    "        dff (dataframe)\n",
    "        message1 (str)\n",
    "    Returns:\n",
    "        dff (dataframe)\n",
    "    \"\"\"\n",
    "    display(message1, dff.shape, dff.head(3)) ; print()\n",
    "    return dff\n",
    "\n",
    "\n",
    "# Chain rule (Chaining)\n",
    "df_processed = (\n",
    "    df\n",
    "   #.pipe(print_details, \"Original DataFrame\")\n",
    "    .drop_duplicates()  \n",
    "    #.pipe(print_details, \"Drop duplicate rows\")\n",
    "    .assign(Passed=lambda x: x['Score'] > 85)  \n",
    "    #.pipe(print_details, \"Assign 'Passed' column based on Score\")\n",
    "    .pivot_table(index='City', columns='Subject', values='Score', aggfunc='mean')  \n",
    "    #.pipe(print_details, \"Pivot table to see average scores per city and subject\")\n",
    "    .reset_index()\n",
    "    .astype({'Math': 'float', 'Physics': 'float', 'Chemistry': 'float'})  \n",
    "    # .pipe(print_details, \"Ensure type casting for pivot table columns\")\n",
    "    .to_csv(\"df_processed.csv\", index=False)\n",
    ")\n",
    "\n",
    "df_processed = pd.read_csv(\"df_processed.csv\")\n",
    "display(\"Final Processed DataFrame:\", df_processed.shape, df_processed.head(3)) ; print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified Data (After Handling Missing Values):\n",
      "    Age     City  Income   Gender\n",
      "0  25.0   Tehran  5000.0     Male\n",
      "1  28.0   Shiraz  6000.0  Unknown\n",
      "2  30.0   Shiraz  5600.0     Male\n",
      "3  22.0  Isfahan  4500.0   Female\n",
      "4  28.0   Tabriz  5500.0   Female\n",
      "5  28.0   Tehran  7000.0  Unknown\n",
      "6  35.0   Tehran  5600.0   Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3249/1055939805.py:21: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_missing['City'] = df_missing['City'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Creating a new dataset with missing values for demonstration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = {\n",
    "    'Age': [25, np.nan, 30, 22, 28, np.nan, 35],\n",
    "    'City': ['Tehran', 'Shiraz', np.nan, 'Isfahan', 'Tabriz', 'Tehran', np.nan],\n",
    "    'Income': [5000, 6000, np.nan, 4500, 5500, 7000, np.nan],\n",
    "    'Gender': ['Male', np.nan, 'Male', 'Female', 'Female', np.nan, 'Female']\n",
    "}\n",
    "\n",
    "df_missing = pd.DataFrame(data)\n",
    "\n",
    "# Before handling missing values\n",
    "df_missing_before = df_missing.copy()\n",
    "\n",
    "# 1. Statistical Imputation (Mean for numeric columns)\n",
    "df_missing['Age'] = df_missing['Age'].fillna(df_missing['Age'].mean())\n",
    "df_missing['Income'] = df_missing['Income'].fillna(df_missing['Income'].mean())\n",
    "\n",
    "# 2. Forward Filling for 'City' column\n",
    "df_missing['City'] = df_missing['City'].fillna(method='ffill')\n",
    "\n",
    "# 3. Custom Imputation for 'Gender' column (impute with 'Unknown')\n",
    "df_missing['Gender'] = df_missing['Gender'].fillna('Unknown')\n",
    "\n",
    "# Showing the data before and after handling missing values\n",
    "print(\"\\nModified Data (After Handling Missing Values):\")\n",
    "print(df_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/samaneh/miniconda3/envs/project4/lib/python3.12/site-packages (from scikit-learn) (2.0.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age       Income     City\n",
      "0  25.0  5000.000000   Tehran\n",
      "1  27.5  6000.000000   Shiraz\n",
      "2  30.0  6071.124134  Isfahan\n",
      "3  22.0  4500.000000      NaN\n",
      "4  28.5  5500.000000   Tabriz\n",
      "5  35.0  7039.424614   Tehran\n",
      "6  40.0  8000.000000  Mashhad\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Creating a dataset with missing values\n",
    "data_simple = {\n",
    "    'Age': [25, np.nan, 30, 22, np.nan, 35, 40],\n",
    "    'Income': [5000, 6000, np.nan, 4500, 5500, np.nan, 8000],\n",
    "    'City': ['Tehran', 'Shiraz', 'Isfahan', np.nan, 'Tabriz', 'Tehran', 'Mashhad']\n",
    "}\n",
    "\n",
    "df_simple = pd.DataFrame(data_simple)\n",
    "\n",
    "# 1. Interpolation (Fix missing 'Age' values before regression)\n",
    "df_simple['Age'] = df_simple['Age'].interpolate(method='linear')\n",
    "\n",
    "# 2. Predictive Imputation (Using linear regression for 'Income' column)\n",
    "df_simple_notna = df_simple.dropna(subset=['Income'])  # Removing rows where 'Income' is NaN\n",
    "X = df_simple_notna[['Age']]  # Independent variable (Age)\n",
    "y = df_simple_notna['Income']  # Dependent variable (Income)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict missing income values\n",
    "income_missing = df_simple[df_simple['Income'].isna()]\n",
    "predicted_income = model.predict(income_missing[['Age']])\n",
    "\n",
    "# Fill the missing 'Income' with predicted values\n",
    "df_simple.loc[df_simple['Income'].isna(), 'Income'] = predicted_income\n",
    "\n",
    "print(df_simple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Income     City  Age_Missing_Flag  Income_Missing_Flag\n",
      "0  25.0  5000.0   Tehran                 0                    0\n",
      "1  30.0  6000.0   Shiraz                 1                    0\n",
      "2  30.0  5500.0  Isfahan                 0                    1\n",
      "3  22.0  4500.0  Missing                 0                    0\n",
      "4  30.0  5500.0   Tabriz                 1                    0\n",
      "5  35.0  5500.0   Tehran                 0                    1\n",
      "6  40.0  8000.0  Mashhad                 0                    0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create a dataset with missing values\n",
    "data = {\n",
    "    'Age': [25, np.nan, 30, 22, np.nan, 35, 40],\n",
    "    'Income': [5000, 6000, np.nan, 4500, 5500, np.nan, 8000],\n",
    "    'City': ['Tehran', 'Shiraz', 'Isfahan', np.nan, 'Tabriz', 'Tehran', 'Mashhad']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Encoding Missing as a Separate Category (For categorical column 'City')\n",
    "df['City'] = df['City'].fillna('Missing')\n",
    "\n",
    "# Step 3: Flagging Missing Values (For numerical columns)\n",
    "df['Age_Missing_Flag'] = df['Age'].isna().astype(int)\n",
    "df['Income_Missing_Flag'] = df['Income'].isna().astype(int)\n",
    "\n",
    "# Step 4: Fill missing values in numerical columns (optional)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())  # Fill with median\n",
    "df['Income'] = df['Income'].fillna(df['Income'].median())  # Fill with median\n",
    "\n",
    "# Print the final dataset\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with Missing Values:\n",
      "     Age  Income  Spending_Score\n",
      "0  25.0  5000.0            65.0\n",
      "1   NaN  6000.0            80.0\n",
      "2  30.0     NaN            70.0\n",
      "3  22.0  4500.0             NaN\n",
      "4   NaN  5500.0            60.0\n",
      "5  35.0     NaN            75.0\n",
      "6  40.0  8000.0             NaN\n",
      "\n",
      "KNN Imputed DataFrame:\n",
      "     Age  Income  Spending_Score\n",
      "0  25.0  5000.0            65.0\n",
      "1  32.5  6000.0            80.0\n",
      "2  30.0  4750.0            70.0\n",
      "3  22.0  4500.0            72.5\n",
      "4  32.5  5500.0            60.0\n",
      "5  35.0  7000.0            75.0\n",
      "6  40.0  8000.0            72.5\n",
      "\n",
      "Multivariate (Iterative) Imputed DataFrame:\n",
      "          Age       Income  Spending_Score\n",
      "0  25.000000  5000.000000       65.000000\n",
      "1  29.854751  6000.000000       80.000000\n",
      "2  30.000000  6028.496285       70.000000\n",
      "3  22.000000  4500.000000       63.519291\n",
      "4  27.310712  5500.000000       60.000000\n",
      "5  35.000000  7009.262620       75.000000\n",
      "6  40.000000  8000.000000       79.634126\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer  # Required for IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Step 1: Create a dataset with missing values\n",
    "data = {\n",
    "    'Age': [25, np.nan, 30, 22, np.nan, 35, 40],\n",
    "    'Income': [5000, 6000, np.nan, 4500, 5500, np.nan, 8000],\n",
    "    'Spending_Score': [65, 80, 70, np.nan, 60, 75, np.nan]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Apply KNN Imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=2)  # Use 2 nearest neighbors\n",
    "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Step 3: Apply Multivariate (Iterative) Imputation\n",
    "iter_imputer = IterativeImputer(max_iter=10, random_state=42)  # Regression-based imputation\n",
    "df_iter_imputed = pd.DataFrame(iter_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Print the original and imputed DataFrames\n",
    "print(\"Original DataFrame with Missing Values:\\n\", df)\n",
    "print(\"\\nKNN Imputed DataFrame:\\n\", df_knn_imputed)\n",
    "print(\"\\nMultivariate (Iterative) Imputed DataFrame:\\n\", df_iter_imputed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
